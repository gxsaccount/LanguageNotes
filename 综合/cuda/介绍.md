## GPU与CPU ##  
<img src=https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png />    
绿色的是计算单元，橙红色的是存储单元，橙黄色的是控制单元.      
       
CPU(低延时):  
CPU有强大计算单元(ALU),可以在少时钟周期内完成计算.  
CPU的时钟周期频率非常高  
CPU的混存较大可以降低延时,增大命中率  
CPU的Control控制单元复杂,可以进行分支预测,数据转发(数据依赖),需要更多的对比,转发电路单元  
GPU(吞吐量):
GPU采用了数量众多的计算单元和超长的流水线.  
GPU只有非常简单的控制逻辑并省去了Cache。  
所以与CPU擅长逻辑控制和通用类型数据运算不同，GPU擅长的是大规模并发计算，这也正是密码破解等所需要的。    
所以GPU除了图像处理，也越来越多的参与到计算当中来。
## 适合的情况 ##  
　　（1）**计算密集型的程序**。所谓计算密集型(Compute-intensive)的程序，就是其大部分运行时间花在了寄存器运算上，寄存器的速度和处理器的速度相当，从寄存器读写数据几乎没有延时。可以做一下对比，读内存的延迟大概是几百个时钟周期；读硬盘的速度就不说了，即便是SSD, 也实在是太慢了。  

　　（2）**易于并行的程序**。GPU其实是一种SIMD(Single Instruction Multiple Data)架构， 他有成百上千个核，每一个核在同一时间最好能做同样的事情。  
　　满足以上两点，就可以用GPU做运算了  
## 三个关键抽象 ##  
**线程组**，**共享内存**和**屏障同步**的层次结构.  
这些抽象提供细粒度数据并行和线程并行，嵌套在粗粒度数据并行和任务并行中。  

## GPU的自动伸缩性 ##  
<img src= https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/automatic-scalability.png/>  
GPU是围绕一组流式多处理器(Streaming Multiprocessors SMs)构建的(有关更多细节，请参见<a text=硬件实现 src= https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation/>)。一个多线程程序被分割成独立执行的线程块，因此一个多处理器的GPU比一个少处理器的GPU在更短的时间内自动执行程序。
v_out
