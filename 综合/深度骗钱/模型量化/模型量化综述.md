## 1.量化定义 ##  
目的:优化离散变量  
(1)矩阵分解  IxJ = (IxR) * (RxJ)  主要为了内存大小占用,使用较少,计算相关问题  
(2)剪枝,将某些参数置为0,对cuda计算无加速, 结构化剪枝(例如将整个chanel去掉,可以加速,减少内存)  
(3) automl,神经网络搜索搜索出一些较小的网络  


## 2.量化挑战##  
正向传播:
1.精度减小,使得模型表达能力不足
2.trade-off:量化范围和精度
3.均匀量化,非均匀量化(效果好,不好实现)  
反向传播:
<img src="https://latex.codecogs.com/gif.latex?h=Q(W_{T}^{f}\times&space;x)" title="h=Q(W_{T}^{f}\times x)" />

<img src="https://latex.codecogs.com/gif.latex?y=P(h)" title="y=P(h)" />
Q为量化函数,f表示float,W为原始参数,x为输入,y为输出

对损失函数L求导:
<img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;L}{W_{f}^{T}}=\frac{\partial&space;y}{\partial&space;h}\frac{\partial&space;h}{Q(W_{f}^{T})}\frac{\partial&space;Q(W_{f}^{T})}{W_{f}^{T}}" title="\frac{\partial L}{W_{f}^{T}}=\frac{\partial y}{\partial h}\frac{\partial h}{Q(W_{f}^{T})}\frac{\partial Q(W_{f}^{T})}{W_{f}^{T}}" />

但是Q,P是离散的函数,求导值为0  


 
